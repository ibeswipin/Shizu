# Shizu Copyright (C) 2023-2024  AmoreForever

# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.

import re
import requests

from pyrogram import types, Client
from .. import loader, utils

# https://raw.githubusercontent.com/MoriSummerz/ftg-mods/main/chatgpt.py


@loader.module("ShizuGpt", "hikamoru", 1.0)
class ShizuGpt(loader.Module):
    """ChatGPT AI API interaction"""

    strings = {
        "set": "<emoji id=5021905410089550576>‚úÖ</emoji> <b>GPT key has been set</b>",
        "what": "<emoji id=5789703785743912485>‚ùî</emoji> What should I set?",
        "what_ask": "<emoji id=5789703785743912485>‚ùî</emoji> What should I ask?",
        "no_token": "<emoji id=5789703785743912485>‚ùî</emoji> Token not set.",
        "pending": "<emoji id=5819167501912640906>‚ùî</emoji> <b>Your Question was:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ü§ñ</emoji> <b>Answer: </b> Wait...",
        "answer": "<emoji id=5819167501912640906>‚ùî</emoji> <b>Your Question was:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ü§ñ</emoji> <b>Answer:</b> {}",
        "cfg_doc": "Here you can set your GPT key, you can get it here: https://platform.openai.com/",
        "cfg_model_doc": "GPT model to use (gpt-3.5-turbo, gpt-4, gpt-4-turbo, etc.)",
        "cfg_temp_doc": "Temperature for responses (0.0-2.0, higher = more creative)",
        "clear_success": "‚úÖ <b>Conversation history cleared</b>",
        "clear_empty": "‚ÑπÔ∏è <b>History is empty</b>",
    }

    strings_ru = {
        "set": "<emoji id=5021905410089550576>‚úÖ</emoji> <b>GPT –∫–ª—é—á —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω</b>",
        "what": "<emoji id=5789703785743912485>‚ùî</emoji> –ß—Ç–æ –Ω—É–∂–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å?",
        "what_ask": "<emoji id=5789703785743912485>‚ùî</emoji> –ß—Ç–æ –Ω—É–∂–Ω–æ –∑–∞–¥–∞—Ç—å?",
        "no_token": "<emoji id=5789703785743912485>‚ùî</emoji> –¢–æ–∫–µ–Ω –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.",
        "pending": "<emoji id=5819167501912640906>‚ùî</emoji> <b>–í–∞—à –≤–æ–ø—Ä–æ—Å:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ü§ñ</emoji> <b>–û—Ç–≤–µ—Ç:</b> –û–∂–∏–¥–∞–Ω–∏–µ...",
        "answer": "<emoji id=5819167501912640906>‚ùî</emoji> <b>–í–∞—à –≤–æ–ø—Ä–æ—Å:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ü§ñ</emoji> <b>–û—Ç–≤–µ—Ç:</b> {}",
        "cfg_doc": "–ó–¥–µ—Å—å –≤—ã –º–æ–∂–µ—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å–≤–æ–π GPT –∫–ª—é—á, –≤—ã –º–æ–∂–µ—Ç–µ –ø–æ–ª—É—á–∏—Ç—å –µ–≥–æ –∑–¥–µ—Å—å: https://platform.openai.com/",
        "cfg_model_doc": "GPT –º–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (gpt-3.5-turbo, gpt-4, gpt-4-turbo –∏ —Ç.–¥.)",
        "cfg_temp_doc": "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ (0.0-2.0, –≤—ã—à–µ = –±–æ–ª–µ–µ –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ)",
        "clear_success": "‚úÖ <b>–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω–∞</b>",
        "clear_empty": "‚ÑπÔ∏è <b>–ò—Å—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞</b>",
    }

    strings_uz = {
        "set": "<emoji id=5021905410089550576>‚úÖ</emoji> <b>GPT kalit ornatildi</b>",
        "what": "<emoji id=5789703785743912485>‚ùî</emoji> Nma ornatishim kerak?",
        "what_ask": "<emoji id=5789703785743912485>‚ùî</emoji> Nma qoldiring?",
        "no_token": "<emoji id=5789703785743912485>‚ùî</emoji> Token not set.",
        "pending": "<emoji id=5819167501912640906>‚ùî</emoji> <b>Yozuv:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ü§ñ</emoji> <b>Javob:</b> O'qiyapman...",
        "answer": "<emoji id=5819167501912640906>‚ùî</emoji> <b>Yozuv:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ü§ñ</emoji> <b>Javob:</b> {}",
        "cfg_doc": "Bu erda siz o'zingizning GPT kalitingizni o'rnatishingiz mumkin, uni ushbu manzilda olishingiz mumkin: https://platform.openai.com/",
        "cfg_model_doc": "Ishlatiladigan GPT modeli (gpt-3.5-turbo, gpt-4, gpt-4-turbo va boshqalar)",
        "cfg_temp_doc": "Javoblar uchun harorat (0.0-2.0, yuqoriroq = yanada ijodkor)",
        "clear_success": "‚úÖ <b>Suhbat tarixi tozalandi</b>",
        "clear_empty": "‚ÑπÔ∏è <b>Tarix bo'sh</b>",
    }

    strings_jp = {
        "set": "<emoji id=5021905410089550576>‚úÖ</emoji> <b>GPT„Ç≠„Éº„ÅåË®≠ÂÆö„Åï„Çå„Åæ„Åó„Åü</b>",
        "what": "<emoji id=5789703785743912485>‚ùî</emoji> ‰Ωï„ÇíË®≠ÂÆö„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„Çä„Åæ„Åô„ÅãÔºü",
        "what_ask": "<emoji id=5789703785743912485>‚ùî</emoji> ‰Ωï„ÇíÂ∞ã„Å≠„ÇãÂøÖË¶Å„Åå„ÅÇ„Çä„Åæ„Åô„ÅãÔºü",
        "no_token": "<emoji id=5789703785743912485>‚ùî</emoji> „Éà„Éº„ÇØ„É≥„ÅåË®≠ÂÆö„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ",
        "pending": "<emoji id=5819167501912640906>‚ùî</emoji> <b>„ÅÇ„Å™„Åü„ÅÆË≥™Âïè„ÅØ:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ü§ñ</emoji> <b>Á≠î„Åà:</b> ÂæÖ„Å£„Å¶„Åè„Å†„Åï„ÅÑ...",
        "answer": "<emoji id=5819167501912640906>‚ùî</emoji> <b>„ÅÇ„Å™„Åü„ÅÆË≥™Âïè„ÅØ:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ü§ñ</emoji> <b>Á≠î„Åà:</b> {}",
        "cfg_doc": "„Åì„Åì„Åß„ÅØGPT„Ç≠„Éº„ÇíË®≠ÂÆö„Åß„Åç„Åæ„Åô„ÄÇ„Åì„Åì„ÅßÂèñÂæó„Åß„Åç„Åæ„ÅôÔºöhttps://platform.openai.com/",
        "cfg_model_doc": "‰ΩøÁî®„Åô„ÇãGPT„É¢„Éá„É´ (gpt-3.5-turbo, gpt-4, gpt-4-turbo„Å™„Å©)",
        "cfg_temp_doc": "ÂøúÁ≠î„ÅÆÊ∏©Â∫¶ (0.0-2.0, È´ò„ÅÑ = „Çà„ÇäÂâµÈÄ†ÁöÑ)",
        "clear_success": "‚úÖ <b>‰ºöË©±Â±•Ê≠¥„Åå„ÇØ„É™„Ç¢„Åï„Çå„Åæ„Åó„Åü</b>",
        "clear_empty": "‚ÑπÔ∏è <b>Â±•Ê≠¥„ÅåÁ©∫„Åß„Åô</b>",
    }

    strings_ua = {
        "set": "<emoji id=5021905410089550576>‚úÖ</emoji> <b>GPT –∫–ª—é—á –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ</b>",
        "what": "<emoji id=5789703785743912485>‚ùî</emoji> –©–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ –≤—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏?",
        "what_ask": "<emoji id=5789703785743912485>‚ùî</emoji> –©–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ –∑–∞–ø–∏—Ç–∞—Ç–∏?",
        "no_token": "<emoji id=5789703785743912485>‚ùî</emoji> –¢–æ–∫–µ–Ω –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ.",
        "pending": "<emoji id=5819167501912640906>‚ùî</emoji> <b>–í–∞—à –∑–∞–ø–∏—Ç–∞–Ω–Ω—è:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ü§ñ</emoji> <b>–í—ñ–¥–ø–æ–≤—ñ–¥—å:</b> –û—á—ñ–∫—É–≤–∞–Ω–Ω—è...",
        "answer": "<emoji id=5819167501912640906>‚ùî</emoji> <b>–í–∞—à –∑–∞–ø–∏—Ç–∞–Ω–Ω—è:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ü§ñ</emoji> <b>–í—ñ–¥–ø–æ–≤—ñ–¥—å:</b> {}",
        "cfg_doc": "–¢—É—Ç –≤–∏ –º–æ–∂–µ—Ç–µ –≤—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ —Å–≤—ñ–π GPT –∫–ª—é—á, –≤–∏ –º–æ–∂–µ—Ç–µ –æ—Ç—Ä–∏–º–∞—Ç–∏ –π–æ–≥–æ —Ç—É—Ç: https://platform.openai.com/",
        "cfg_model_doc": "GPT –º–æ–¥–µ–ª—å –¥–ª—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è (gpt-3.5-turbo, gpt-4, gpt-4-turbo —Ç–æ—â–æ)",
        "cfg_temp_doc": "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π (0.0-2.0, –≤–∏—â–µ = –±—ñ–ª—å—à –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ)",
        "clear_success": "‚úÖ <b>–Ü—Å—Ç–æ—Ä—ñ—è –¥—ñ–∞–ª–æ–≥—É –æ—á–∏—â–µ–Ω–∞</b>",
        "clear_empty": "‚ÑπÔ∏è <b>–Ü—Å—Ç–æ—Ä—ñ—è –ø–æ—Ä–æ–∂–Ω—è</b>",
    }

    strings_kz = {
        "set": "<emoji id=5021905410089550576>‚úÖ</emoji> <b>GPT —Ç—ñ—Ä–∫–µ–ª–¥—ñ</b>",
        "what": "<emoji id=5789703785743912485>‚ùî</emoji> –ù–µ–Ω—ñ –æ—Ä–Ω–∞—Ç—É –∫–µ—Ä–µ–∫?",
        "what_ask": "<emoji id=5789703785743912485>‚ùî</emoji> –ù–µ–Ω—ñ —Å“±—Ä–∞—É –∫–µ—Ä–µ–∫?",
        "no_token": "<emoji id=5789703785743912485>‚ùî</emoji> –¢–æ–∫–µ–Ω –æ—Ä–Ω–∞—Ç—ã–ª–º–∞“ì–∞–Ω.",
        "pending": "<emoji id=5819167501912640906>‚ùî</emoji> <b>–°“±—Ä–∞“ì—ã“£—ã–∑:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ü§ñ</emoji> <b>–ñ–∞—É–∞–±—ã:</b> –ö“Ø—Ç—É...",
        "answer": "<emoji id=5819167501912640906>‚ùî</emoji> <b>–°“±—Ä–∞“ì—ã“£—ã–∑:</b> <code>{}</code>\n\n<emoji id=5372981976804366741>ü§ñ</emoji> <b>–ñ–∞—É–∞–±—ã:</b> {}",
        "cfg_doc": "–ú“±–Ω–¥–∞ —Å—ñ–∑ –æ“ì–∞–Ω —Ç“Ø—Å—ñ–Ω—ñ–∫—Ç–µ–º–µ –±–µ—Ä–µ—Ç—ñ–Ω GPT —Ç—ñ—Ä–∫–µ–ª–≥—ñ“£—ñ–∑–¥—ñ –æ—Ä–Ω–∞—Ç—É“ì–∞ –±–æ–ª–∞–¥—ã: https://platform.openai.com/",
        "cfg_model_doc": "–ü–∞–π–¥–∞–ª–∞–Ω—ã–ª–∞—Ç—ã–Ω GPT –º–æ–¥–µ–ª—ñ (gpt-3.5-turbo, gpt-4, gpt-4-turbo –∂”ô–Ω–µ —Ç.–±.)",
        "cfg_temp_doc": "–ñ–∞—É–∞–ø—Ç–∞—Ä “Ø—à—ñ–Ω —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ (0.0-2.0, –∂–æ“ì–∞—Ä—ã = –≥“Ø–ª–¥–µ–Ω–≥–µ–Ω)",
        "clear_success": "‚úÖ <b>–î–∏–∞–ª–æ–≥ —Ç–∞—Ä–∏—Ö—ã —Ç–∞–∑–∞—Ä—Ç—ã–ª–¥—ã</b>",
        "clear_empty": "‚ÑπÔ∏è <b>–¢–∞—Ä–∏—Ö –±–æ—Å</b>",
    }

    def __init__(self):
        self.config = loader.ModuleConfig(
            "GPT_KEY", None, lambda m: self.strings("cfg_doc"),
            "GPT_MODEL", "gpt-4o-mini", lambda m: self.strings("cfg_model_doc"),
            "GPT_TEMPERATURE", 0.7, lambda m: self.strings("cfg_temp_doc"),
        )
        self._conversation_history = {} 

    async def _make_request(
        self,
        method: str,
        url: str,
        headers: dict,
        data: dict,
    ) -> dict:
        """
        Makes an asynchronous HTTP request using the specified method, URL,
        headers, and data.

        Parameters:
            method (str): The HTTP method to use for the request.
            url (str): The URL to send the request to.
            headers (dict): The headers to include in the request.
            data (dict): The JSON data to include in the request body.

        Returns:
            dict: The JSON response from the server.
        """
        resp = await utils.run_sync(
            requests.request,
            method,
            url,
            headers=headers,
            json=data,
        )
        return resp.json()

    def _process_code_tags(self, text: str) -> str:
        """Improved code block processing with language support"""
        text = re.sub(
            r"```(\w+)?\n?(.*?)```",
            r"<code>\2</code>",
            text,
            flags=re.DOTALL,
        )
        text = re.sub(r"`([^`]+)`", r"<code>\1</code>", text)
        return text
    
    def _get_system_prompt(self) -> str:
        """Enhanced system prompt for better responses"""
        return """You are a helpful, intelligent, and creative AI assistant. 
- Provide clear, detailed, and well-structured answers
- Use proper formatting with code blocks when sharing code
- Be concise but comprehensive
- Adapt your communication style to the user's needs
- If asked to explain code, provide thorough explanations
- For creative tasks, be imaginative and engaging
- Always prioritize accuracy and helpfulness"""

    async def _get_chat_completion(
        self, prompt: str, token: str, chat_id: int = None
    ) -> str:
        """Enhanced chat completion with conversation history and better prompts"""
        model = self.config.get("GPT_MODEL", "gpt-4o-mini")
        temperature = float(self.config.get("GPT_TEMPERATURE", 0.7))
        
        messages = [{"role": "system", "content": self._get_system_prompt()}]
        
        if chat_id and chat_id in self._conversation_history:
            messages.extend(self._conversation_history[chat_id][-10:])  
        
        
        messages.append({"role": "user", "content": prompt})
        
        resp = await self._make_request(
            method="POST",
            url="https://api.openai.com/v1/chat/completions",
            headers={
                "Content-Type": "application/json",
                "Authorization": f"Bearer {token}",
            },
            data={
                "model": model,
                "messages": messages,
                "temperature": temperature,
                "max_tokens": 2000,
            },
        )
        
        if resp.get("error", None):
            return f"üö´ {resp['error']['message']}"

        assistant_message = resp["choices"][0]["message"]["content"]
        
        if chat_id:
            if chat_id not in self._conversation_history:
                self._conversation_history[chat_id] = []
            self._conversation_history[chat_id].append({"role": "user", "content": prompt})
            self._conversation_history[chat_id].append({"role": "assistant", "content": assistant_message})
            if len(self._conversation_history[chat_id]) > 20:
                self._conversation_history[chat_id] = self._conversation_history[chat_id][-20:]

        return assistant_message

    @loader.command()
    async def gpt(self, app: Client, message: types.Message):
        """Ask question to GPT"""
        args = message.get_args_raw()

        if not args:
            return await message.answer(self.strings("what_ask"))

        token = self.config["GPT_KEY"]
        if not token:
            return await message.answer(self.strings("no_token"))
        
        chat_id = message.chat.id if message.chat else None
        
        msg = await message.answer(self.strings("pending").format(args))
        answer = await self._get_chat_completion(args, token, chat_id)
        await utils.answer(
            msg, self.strings("answer").format(args, self._process_code_tags(answer))
        )
    
    @loader.command()
    async def gptclear(self, app: Client, message: types.Message):
        """Clear conversation history"""
        chat_id = message.chat.id if message.chat else None
        if chat_id and chat_id in self._conversation_history:
            del self._conversation_history[chat_id]
            await message.answer(self.strings("clear_success"))
        else:
            await message.answer(self.strings("clear_empty"))
